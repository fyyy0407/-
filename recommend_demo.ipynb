{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbeb55de",
   "metadata": {},
   "source": [
    "# 推荐系统demo\n",
    "本notebook是一个推荐系统的简单demo，可以用于各种推荐模型的简单测试。\n",
    "\n",
    "同目录下的utils.py包含一些数据处理和模型训练流程的通用代码，dataset文件夹下面包含三个数据集\n",
    "- MovieLens数据集，仅包含user和item的id以及评分\n",
    "- criteo数据集，包含数十个离散型特征和连续型特征\n",
    "- Amazon数据集，包含用户的历史行为特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74346116",
   "metadata": {},
   "source": [
    "推荐使用conda安装所需的包，包括：\n",
    "- pytorch\n",
    "- numpy\n",
    "- pandas\n",
    "- sklearn\n",
    "- matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b8f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e985d901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on [cpu].\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Training on [{}].'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c95c86",
   "metadata": {},
   "source": [
    "下面的代码块准备了movielens数据集，可以更换为另外两种数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ce08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_dataset\n",
    "dataset = create_dataset('movielens', device=device)\n",
    "data = dataset.train_valid_test_split()\n",
    "field_dims, (train_X, train_y), (valid_X, valid_y), (test_X, test_y) = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb6c90",
   "metadata": {},
   "source": [
    "下面的代码块定义了一个简单的模型，将embedding合并之后通过一层全连接层和sigmoid激活函数，之后直接输出。\n",
    "\n",
    "依照论文实现其他模型时在这里修改模型结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4ed5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(torch.nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim = 4):\n",
    "        super(model, self).__init__()\n",
    "        print(field_dims)\n",
    "        self.embedding_list = torch.nn.ModuleList([torch.nn.Embedding(dim, embed_dim) for dim in field_dims])\n",
    "        print(self.embedding_list)\n",
    "        self.linear = torch.nn.Linear(len(field_dims)*embed_dim, 1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        all_emb = torch.cat([embedding(X[:, i]) for i, embedding in enumerate(self.embedding_list)], dim = 1)\n",
    "        logit = self.linear(all_emb)\n",
    "        return F.sigmoid(logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24853ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[611, 193610]\n",
      "ModuleList(\n",
      "  (0): Embedding(611, 8)\n",
      "  (1): Embedding(193610, 8)\n",
      ")\n",
      "torch.Size([80000, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [00:02<02:10,  7.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m\n",
      "File \u001b[0;32m~/recommendation/utils.py:251\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_X, train_y, epoch, trials, valid_X, valid_y)\u001b[0m\n\u001b[1;32m    248\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 251\u001b[0m     train_loss_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(b_x)\n\u001b[1;32m    253\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(train_loss_\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_X))\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# valid part\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from utils import Trainer\n",
    "EMBEDDING_DIM = 8\n",
    "LEARNING_RATE = 1e-4\n",
    "REGULARIZATION = 1e-6\n",
    "BATCH_SIZE = 4096\n",
    "EPOCH = 1000\n",
    "TRIAL = 100\n",
    "\n",
    "mm = model(field_dims, EMBEDDING_DIM).to(device)\n",
    "optimizer = torch.optim.Adam(mm.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZATION)\n",
    "criterion = torch.nn.BCELoss()\n",
    "print(train_X.shape)\n",
    "# print(mm(train_X[0].unsqueeze(0)))\n",
    "trainer = Trainer(mm, optimizer, criterion, BATCH_SIZE)\n",
    "trainer.train(train_X, train_y, epoch=EPOCH, trials=TRIAL, valid_X=valid_X, valid_y=valid_y)\n",
    "test_loss, test_auc = trainer.test(test_X, test_y)\n",
    "print('test_loss:  {:.5f} | test_auc:  {:.5f}'.format(test_loss, test_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c92a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
